\section{Counting objects in images}
\label{sec:counting_objs}

Counting objects in digital images is a common task for many real-world applications \cite{segui2015learning, arteta2016counting, paul2017countception, rahnemoonfar2017deepfruit} and different approaches have been explored to automate it \cite{lempitsky2010learning, ciresan2012deep, cirecsan2013mitosis, Kraus2016, Raza2017}. 

Multiple paradigms for counting objects in images have been proposed depending on the study's specific needs and the available data.
The natural setting to tackle this problem is the so-called \textit{counting-by-regression} scheme. 
In this case, the input data consist of the image and, optionally, other features. 
The model is then trained to output the raw count of objects directly. However, this approach does not provide any immediate justification of which elements generated the final count.
Another strategy is \textit{counting-by-detection}.
In this case, the model is trained to reproduce ground-truth masks having bounding boxes surrounding the objects to detect. 
In this way, the output becomes an image where pixels are classified either into the signal class (within the boxes) or as background (outside). 
This outcome provides the raw count as the number of sets of connected pixels, plus a justification in terms of the localization furnished by the bounding boxes. 
Building on the latter framework, one can refine the model's ability to detect and localize the objects by including semantic labels for each pixel in the ground-truth masks. This allows pixel-wise classification that enables to discern the exact boundaries of each object. The total count is then retrieved again by looking at groups of connected pixels. Such an approach is referred to as \textit{counting-by-segmentation}.
This work is framed under the latter paradigm so to support the results with a clear, visual evidence of which objects contribute to the final counts.

\subsection{Related works}
\label{sec:related_works}

Some interesting approaches have been proposed for detecting and counting cells in microscopic images.
\citeA{Faustino2009} propose an automated method leveraging the luminance information to generate a graph representation from which counts of cells are retrieved after a careful mining process. Nonetheless, their approach relies on the manual setting of some parameters, like the optimal threshold for separating cell clusters and the luminance histogram binning adopted for retrieving connected components, which hampers the extension to different data.

\citeA{unet} present a Deep Learning approach for segmentation of cells in an image. 
Their main contribution is the introduction of a novel network architecture, \textit{U-Net}, which is still state-of-the-art in several applications with only slight adaptations \cite{masin2021novel, ritch2020axonet}. 
The basic idea is to have an initial contracting branch used to capture relevant features, and a symmetric expanding one that allows for accurate localization.
The main drawback is that its enormous number of parameters requires relevant computing power and makes the training difficult because of vanishing gradient \cite{vanishing_gradient}. 
For this reason, a commonly used variation adopts residual units \cite{residual_units} with short-range skip-connections and batch normalization to prevent that problem.
Also, this typically guarantees comparable performance with much less parameters.

% Two further proposals are detailed in the 2016 Kraus et al. \cite{Kraus2016} paper and in the 2017 Raza et al. \cite{Raza2017} paper.
\citeA{Kraus2016} combine deep CNNs with multiple instance learning in order to classify and segment microscopy images using only whole image level annotations. 
\citeA{Raza2017} propose a novel multiple-input multiple-output convolution neural network (MIMO-Net) that utilizes multiple resolutions of the input image, connects the intermediate layers for better localization and context and generates the output using multi-resolution deconvolution filters.

A common downside of these approaches is  the need of ground-truth labels (or masks) with accurate annotations of whether each pixel belongs to an object -- in this case a cell -- or the background, resulting in an additional and laborious data preparation phase.
% Two further interesting approaches that have been considered are detailed in the 2016 Kraus et al. \cite{Kraus2016} paper and in the 2017 Raza et al. \cite{Raza2017} paper.
% The former suggested a method that combined deep CNNs with multiple instance learning (MIL) in order to classify and segment microscopy images using only whole image level annotations. The latter proposed a novel multiple-input multiple-output convolution neural network (MIMO-Net) that utilizes multiple resolutions of the input image, connects the intermediate layers for better localization and context and generates the output using multi-resolution deconvolution filters.
In an attempt to overcome this limitation, some works try to tackle the problem in an unsupervised fashion. For example, \citeA{Riccio2019} address segmentation and counting with a step-wise procedure. The whole image is first split into square patches, and a combination of gray level clustering followed by adaptive thresholding is adopted for foreground/background separation. Individual cells are then labeled by detecting their centers and applying a region growing process. 
While this procedure bypasses the need for ground-truth masks, it still requires handcrafted hyperparameters selection that needs to be tuned for new data.
For additional examples of segmentation in biological images, the interested reader is referred to \citeA{Riccio2019}.