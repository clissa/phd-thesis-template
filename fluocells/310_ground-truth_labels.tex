\section{Ground-truth labels}
Under a supervised learning framework, the training phase leverages ground-truth labels acting as examples of desired outputs that the model should learn to reproduce. 
In the case of image segmentation, such targets are in the form of binary images (\textit{masks}) where the objects to segment and the background are represented by white and black pixels, respectively 
% (\cref{fig:dataset}, right).
(\cref{fig:dataset:empty_mask,fig:dataset:dark_mask,fig:dataset:bright_mask}).

Obtaining target masks usually requires a great effort in terms of time and human resources, so an initial automatic procedure was exploited to speed up the labeling process. 
In particular, starting from a large subset composed by 252 pictures, gaussian blurring (with size $\sigma=7$)\footnote{the \texttt{skimage.filters.gaussian} utils was adopted for this task} was first applied to mitigate small-frequency noise. 
Then, the resulting images were subjected to a thresholding operation.
% using a cutoff selected base on the pixel intensity histogram shape. 
For this step, the image histogram of the pixel intensity was considered, and a cutoff equal to the 97\emph{-th} percentile of the intensity distribution was adopted for binarization. 
The goal was to obtain a loose selection of good candidates to be labeled as neuronal cells. 
After that, knowledgeable operators reviewed the results to discard the false positives introduced with the previous procedure, taking care of excluding irrelevant artifacts and misleading biological structures.
The remaining 31 images were segmented manually by domain experts. Significant pictures with challenging traits -- such as artifacts, filaments and cell agglomerates (see \cref{sec:challenges}) -- were included in the latter set to have highly reliable masks for the most arduous examples\footnote{check the \emph{README} file in \citeA{clissa2021fluocells} for the list of manually segmented images}. 
% (see $link_to_github$ for more details).

% \lc{A summary of the distributions of counts and objects features is presented in Table \ref{tab:dataset_summary}}.
% % ...possibly add geometrical information of cell objects, average/median/max/min counts per image, ... others(?)
% \begin{table}[b]
% \begin{center}
% \begin{tabular}{cccccc}
% \hline
% area    & minor axis & major axis & equivalent diameter & maximum feret diameter & mean diameter \\
% \hline
% 1206.43 & 29.39 & 50.43 & 36.50 & 55.34 & 47.42\\
% \hline
% \end{tabular}
% \caption{Summary statistics of cells morphological features (measured in pixels)}
% \label{tab:dataset_summary}
% \end{center}
% \end{table}


Despite the huge popularity Deep Learning has gained in computer vision in the last decade, the lack of annotated data is a common curse when dealing with applications involving non-standard images and/or tasks \cite{curse_dataset_annotation}. 
Since ground-truth labels are expensive to acquire in terms of time and costs \cite{vija2009annotationcost, mullen2019comparing}, a common approach is to fine-tune models that are pre-trained on giants datasets of natural images like ImageNet \cite{ImageNet} or COCO \cite{COCO}, possibly using as few new labels as possible for the task of interest. 
However, this strategy often does not apply to use cases where the pictures under analysis belong to extraneous domains with respect to the ones used for pre-training \cite{TL_medical_imaging}.
For this reason, by releasing the annotated dataset\footnote{\dataset} and the pre-trained model\footnote{\linkmodel} we hope to \textit{i)} foster advances in fields like biomedical imaging through the speed up guaranteed by the automation of manual operations, and \textit{ii)} promote methodological research on new techniques of data analysis for microscopic fluorescence and similar domains.
