\section{Model training}
\label{sec:model_training}

After randomly setting 70 full-size images apart as a test set, the remaining pictures were randomly split into training and validation sets. 
In particular, twelve $512\times512$ partially overlapping crops were extracted from each image and fed as input to the network after undergoing a standard augmentation pipeline. Common transformations were considered as rotations, addition of Gaussian noise, brightness variation and elastic transformations \cite{elastic_tranformation}. 
The augmentation factors of the crops were fixed differentially based on their contents. 
The six patches included in the artifact oversampling ablation study were re-sampled 25 times each.
Instead, all the remaining crops produced 10 augmented versions for manually segmented images and 4 for all the others.
As a result, the model was trained on a total of nearly 16000 images (70\% for training and 30\% for validation).

All competing architectures were trained from scratch under the same conditions to favor a fair comparison.
Specifically, the Adam \cite{adam} optimizer was employed with an initial learning rate of 0.006. A scheduled decrease of 30\% was then applied if the validation loss did not improve for 4 consecutive epochs. 
A \textbf{weighted binary cross-entropy} loss was adopted on top of the weight maps to handle the imbalance of the two classes (weights equal to 1.5 and 1 for cells and background, respectively).
All models were trained until no improvement was observed for 20 consecutive epochs. In this way, each model was allowed to converge and the comparison was made at the best of each architecture's capabilities.

The approach was implemented through Keras API \cite{keras} using \texttt{TensorFlow} \cite{tensorflow} as backend. For more details, please refer to the GitHub repository\footnote{\github}.
The training was performed on 4 V100 GPUs provided by the \textit{Centro Nazionale Analisi Fotogrammi} (CNAF)\footnote{\cnaf} computing center of the \textit{National Institute for Nuclear Physics}\footnote{\infn} in Bologna.
In terms of 