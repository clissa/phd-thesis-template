\subsection{Related works}
\label{sec:related_works}

Some interesting approaches have been proposed for detecting and counting cells in microscopic images.
\citeA{Faustino2009} propose an automated method leveraging the luminance information to generate a graph representation from which counts of cells are retrieved after a careful mining process. Nonetheless, their approach relies on the manual setting of some parameters, like the optimal threshold for separating cell clusters and the luminance histogram binning adopted for retrieving connected components, which hampers the extension to different data.

\citeA{unet} present a Deep Learning approach for segmentation of cells in an image. 
Their main contribution is the introduction of a novel network architecture, \textit{U-Net}, which is still state-of-the-art in several applications with only slight adaptations \cite{masin2021novel, ritch2020axonet}. 
The basic idea is to have an initial contracting branch used to capture relevant features, and a symmetric expanding one that allows for accurate localization.
The main drawback is that its enormous number of parameters requires relevant computing power and makes the training difficult because of vanishing gradient \cite{vanishing_gradient, denseUnet2d, cao2020denseunet, qamar2020variant}. 
For this reason, a commonly used variation adopts residual units \cite{residual_units} with short-range skip-connections and batch normalization to prevent that problem.
Also, this typically guarantees comparable performance with much less parameters.

% Two further proposals are detailed in the 2016 Kraus et al. \cite{Kraus2016} paper and in the 2017 Raza et al. \cite{Raza2017} paper.
\citeA{Kraus2016} combine deep CNNs with multiple instance learning in order to classify and segment microscopy images using only whole image level annotations. 
\citeA{Raza2017} propose a novel multiple-input multiple-output convolution neural network (MIMO-Net) that utilizes multiple resolutions of the input image, connects the intermediate layers for better localization and context and generates the output using multi-resolution deconvolution filters.

A common downside of these approaches is  the need of ground-truth labels (or masks) with accurate annotations of whether each pixel belongs to an object -- in this case a cell -- or the background, resulting in an additional and laborious data preparation phase.
% Two further interesting approaches that have been considered are detailed in the 2016 Kraus et al. \cite{Kraus2016} paper and in the 2017 Raza et al. \cite{Raza2017} paper.
% The former suggested a method that combined deep CNNs with multiple instance learning (MIL) in order to classify and segment microscopy images using only whole image level annotations. The latter proposed a novel multiple-input multiple-output convolution neural network (MIMO-Net) that utilizes multiple resolutions of the input image, connects the intermediate layers for better localization and context and generates the output using multi-resolution deconvolution filters.
In an attempt to overcome this limitation, some works try to tackle the problem in an unsupervised fashion. For example, \citeA{Riccio2019} address segmentation and counting with a step-wise procedure. The whole image is first split into square patches, and a combination of gray level clustering followed by adaptive thresholding is adopted for foreground/background separation. Individual cells are then labeled by detecting their centers and applying a region growing process. 
While this procedure bypasses the need for ground-truth masks, it still requires handcrafted hyperparameters selection that needs to be tuned for new data.
For additional examples of segmentation in biological images, the interested reader is referred to \citeA{Riccio2019}.

% \newpage